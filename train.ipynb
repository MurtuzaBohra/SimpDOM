{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the source code auto reloads into the kernel\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To help preventing shared maemory errors\n",
    "!ulimit -n 64000\n",
    "import torch.multiprocessing\n",
    "torch.multiprocessing.set_sharing_strategy('file_system')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:33:10 INFO (3548147748:12): Epoch: 1/1, web-sites: ['auto-aol', 'auto-yahoo']\n",
      "13:33:10 INFO (train_and_eval:36): Loading ./data/English_charDict.pkl\n",
      "13:33:10 INFO (train_and_eval:38): Dictionary ./data/English_charDict.pkl length: 85\n",
      "13:33:10 INFO (train_and_eval:36): Loading ./data/HTMLTagDict.pkl\n",
      "13:33:10 INFO (train_and_eval:38): Dictionary ./data/HTMLTagDict.pkl length: 39\n",
      "13:33:10 INFO (train_and_eval:51): Instantiating the Model checkpoint.\n",
      "13:33:10 INFO (train_and_eval:61): Instantiating the Sequential model\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training websites - ['auto-aol']\n",
      "validation websites - ['auto-yahoo']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:33:15 INFO (train_and_eval:84): Instantiating the Training object\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained word vectors loaded - 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/accelerator_connector.py:447: LightningDeprecationWarning: Setting `Trainer(gpus=0)` is deprecated in v1.7 and will be removed in v2.0. Please use `Trainer(accelerator='gpu', devices=0)` instead.\n",
      "  rank_zero_deprecation(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "13:33:15 INFO (train_and_eval:87): Fitting the model\n",
      "\n",
      "  | Name                    | Type             | Params\n",
      "-------------------------------------------------------------\n",
      "0 | charLevelWordEmbeddings | CharCNN          | 6.3 K \n",
      "1 | BiLSTM                  | BiLSTM           | 241 K \n",
      "2 | BiLSTM_xpath            | BiLSTM_xpath     | 12.2 K\n",
      "3 | Leaf_embedding          | Embedding        | 1.2 K \n",
      "4 | pos_embedding           | Embedding        | 2.0 K \n",
      "5 | classifier              | Sequential       | 46.1 K\n",
      "6 | loss                    | CrossEntropyLoss | 0     \n",
      "-------------------------------------------------------------\n",
      "309 K     Trainable params\n",
      "0         Non-trainable params\n",
      "309 K     Total params\n",
      "1.238     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d8f2fa265d408e9e379d8b3c0d64fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Web sites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ed1554743c40fdaa3a701823f2306f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Web pages:   0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13:33:19 INFO (swde_dataLoader:151): SWDE data loader has loaded: 21945 nodes\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_val_loss - 1.5399844646453857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:98: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 32. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7f9bc0d129f4a1da390ef48eabf1fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Web sites:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9042965bbf4f1685759100782849c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Web pages:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "14:47:23 INFO (swde_dataLoader:151): SWDE data loader has loaded: 216164 nodes\n",
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:236: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94ce160da4f64405af5a66bc36b13c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/pytorch_lightning/utilities/data.py:98: UserWarning: Trying to infer the `batch_size` from an ambiguous collection. The batch size we found is 25. To avoid any miscalculations, use `self.log(..., batch_size=batch_size)`.\n",
      "  warning_cache.warn(\n",
      "Epoch 0, global step 6756: 'val_loss' reached 0.00000 (best 0.00000), saving model to '/Users/izapreev/Projects/SimpDOM/lightning_logs/version_2/checkpoints/./data/weights.ckpt' as top 1\n",
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n",
      "14:53:37 INFO (train_and_eval:90): Saving the check point\n",
      "14:53:37 INFO (train_and_eval:93): Re-loading the Sequential model from Checkpoint\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_val_loss - 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:53:41 INFO (3548147748:14): Training is finished, starting predicting\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained word vectors loaded - 400000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:53:45 INFO (swde_dataLoader:236): Start loading data set for websites: ['auto-yahoo']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained word vectors loaded - 400000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbac6dd4de2a4b6da4e4753774f93589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Web site:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29522ba00171494e9c19b974a58735d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Web pages:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n",
      "IOStream.flush timed out\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 218854 - nodes are loaded in swde_dataLoader_test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/numpy/core/fromnumeric.py:3432: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "/Users/izapreev/miniforge3/envs/tfm/lib/python3.8/site-packages/numpy/core/_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "15:38:18 INFO (3548147748:16): Test predictions result: {1: (1.0, nan, nan), 2: (1.0, nan, nan), 3: (1.0, nan, nan), 4: (1.0, nan, nan)}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class - 1: precision = 1.0, recall = nan, F1 = nan\n",
      "class - 2: precision = 1.0, recall = nan, F1 = nan\n",
      "class - 3: precision = 1.0, recall = nan, F1 = nan\n",
      "class - 4: precision = 1.0, recall = nan, F1 = nan\n"
     ]
    }
   ],
   "source": [
    "#n permutations of train and validation sets for average PR results.\n",
    "import random\n",
    "import pickle\n",
    "from train_and_eval import train, test\n",
    "from Utils.logger import logger\n",
    "websites = ['auto-aol','auto-yahoo']#['auto-aol','auto-yahoo','auto-motortrend','auto-autobytel', 'auto-msn' ]\n",
    "attributes = ['model', 'price', 'engine', 'fuel_economy']\n",
    "n=1\n",
    "list_avg_pr = []\n",
    "for itr in range(n):\n",
    "    random.shuffle(websites)\n",
    "    logger.info(f'Epoch: {itr+1}/{n}, web-sites: {websites}')\n",
    "    val_websites, charDict, tagDict, model, n_classes = train(websites, attributes)\n",
    "    logger.info(f'Training is finished, starting predicting')\n",
    "    avg_pr_dict = test(val_websites, charDict, tagDict, model, n_classes)\n",
    "    logger.info(f'Test predictions result: {avg_pr_dict}')\n",
    "    list_avg_pr.append(avg_pr_dict)\n",
    "    pickle.dump(list_avg_pr, open('./list_avg_pr.pkl', 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To Create the training data for other verticals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy\n",
    "import os\n",
    "from Utils.DOMTree import DOMTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Datapath = './data' #directory path where each vertical's html pages from SWDE dataset (website wise folders)\n",
    "vertical = 'auto'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['auto-kbb(2000)', 'auto-autoweb(2000)', 'auto-aol(2000)', 'auto-yahoo(2000)', 'auto-motortrend(1267)', 'auto-autobytel(2000)', 'auto-carquotes(2000)', 'auto-cars(657)', 'auto-msn(2000)', 'auto-automotive(1999)']\n",
      "auto-kbb 2000\n",
      "163\n",
      "auto-autoweb 2000\n",
      "286\n",
      "auto-aol 2000\n",
      "517\n",
      "auto-yahoo 2000\n",
      "715\n",
      "auto-motortrend 1267\n",
      "932\n",
      "auto-autobytel 2000\n",
      "1130\n",
      "auto-carquotes 2000\n",
      "1239\n",
      "auto-cars 657\n",
      "1338\n",
      "auto-msn 2000\n",
      "1651\n",
      "auto-automotive 1999\n",
      "1973\n"
     ]
    }
   ],
   "source": [
    "#dataset processor: to find the set of fixed nodes for each of the websites\n",
    "from DatasetCreation.storeFixedNodes import main\n",
    "main(Datapath, vertical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['auto-kbb(2000)', 'auto-autoweb(2000)', 'auto-aol(2000)', 'auto-yahoo(2000)', 'auto-motortrend(1267)', 'auto-autobytel(2000)', 'auto-carquotes(2000)', 'auto-cars(657)', 'auto-msn(2000)', 'auto-automotive(1999)']\n",
      "auto-kbb\n",
      "avg no. of variable nodes = [113.325  149.8585]\n",
      "=====================\n",
      "auto-autoweb\n",
      "avg no. of variable nodes = [ 42.697  117.3055]\n",
      "=====================\n",
      "auto-aol\n",
      "avg no. of variable nodes = [108.082  215.0985]\n",
      "=====================\n",
      "auto-yahoo\n",
      "avg no. of variable nodes = [109.427  182.2715]\n",
      "=====================\n",
      "auto-motortrend\n",
      "avg no. of variable nodes = [ 25.23914759 204.31412786]\n",
      "=====================\n",
      "auto-autobytel\n",
      "avg no. of variable nodes = [ 41.712 191.237]\n",
      "=====================\n",
      "auto-carquotes\n",
      "avg no. of variable nodes = [39.8235 99.8315]\n",
      "=====================\n",
      "auto-cars\n",
      "avg no. of variable nodes = [52.79604262 90.49467275]\n",
      "=====================\n",
      "auto-msn\n",
      "avg no. of variable nodes = [ 95.1715 283.4425]\n",
      "=====================\n",
      "auto-automotive\n",
      "avg no. of variable nodes = [ 77.32616308 298.83491746]\n",
      "=====================\n"
     ]
    }
   ],
   "source": [
    "#dataset processor: Store each website as pickle file\n",
    "from DatasetCreation.storeAllTextNodes import main\n",
    "main(Datapath, vertical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-kbb\n",
      "average friend nodes - 9.361369733580359, partner nodes - 0.12720799769649557\n",
      "===========================\n",
      "auto-autoweb\n",
      "average friend nodes - 9.178472910445214, partner nodes - 0.8818057195648655\n",
      "===========================\n",
      "auto-aol\n",
      "average friend nodes - 8.862153685773654, partner nodes - 0.21809872754387077\n",
      "===========================\n",
      "auto-yahoo\n",
      "average friend nodes - 9.035792462159163, partner nodes - 0.34364432964678576\n",
      "===========================\n",
      "auto-motortrend\n",
      "average friend nodes - 5.614116323088254, partner nodes - 0.09452934092421043\n",
      "===========================\n",
      "auto-autobytel\n",
      "average friend nodes - 9.51733666413649, partner nodes - 0.4654751145337193\n",
      "===========================\n",
      "auto-carquotes\n",
      "average friend nodes - 8.938866956567063, partner nodes - 0.37580329100302323\n",
      "===========================\n",
      "auto-cars\n",
      "average friend nodes - 9.429029676957922, partner nodes - 0.5336563050405798\n",
      "===========================\n",
      "auto-msn\n",
      "average friend nodes - 9.205392640513809, partner nodes - 0.320845476101988\n",
      "===========================\n",
      "auto-automotive\n",
      "average friend nodes - 8.29912641327332, partner nodes - 0.5069163978988117\n",
      "===========================\n"
     ]
    }
   ],
   "source": [
    "#dataset processor: append the friendCircle of each node in the DOMTree\n",
    "from Utils.friendCircleExtractioin import main\n",
    "main(Datapath, vertical, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auto-kbb\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/groundTruth/auto/auto-kbb-model.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m attributes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmanufacturer\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mDatasetCreation\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01massignGroundTruthToEachNode\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDatapath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/SimpDOM/DatasetCreation/assignGroundTruthToEachNode.py:68\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(Datapath, vertical, attributes)\u001b[0m\n\u001b[1;32m     66\u001b[0m nodesDetailsAllPages \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/nodesDetails/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Datapath, website), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attribute \u001b[38;5;129;01min\u001b[39;00m attributes:\n\u001b[0;32m---> 68\u001b[0m \tgroundTruth \u001b[38;5;241m=\u001b[39m \u001b[43m_read_groundTruth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDatapath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvertical\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwebsite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattribute\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \tnodesDetailsAllPages, annotation_statistics \u001b[38;5;241m=\u001b[39m _annotate_gt(nodesDetailsAllPages, groundTruth, label_indices[attribute], annotation_statistics, website, attribute)\n\u001b[1;32m     70\u001b[0m pickle\u001b[38;5;241m.\u001b[39mdump(nodesDetailsAllPages, \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/nodesDetails/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.pkl\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Datapath, website), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/Projects/SimpDOM/DatasetCreation/assignGroundTruthToEachNode.py:16\u001b[0m, in \u001b[0;36m_read_groundTruth\u001b[0;34m(Datapath, vertical, website, attribute)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_groundTruth\u001b[39m(Datapath, vertical, website, attribute):\n\u001b[1;32m     15\u001b[0m \tgroundTruth_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/groundTruth/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(Datapath, vertical, website, attribute)\n\u001b[0;32m---> 16\u001b[0m \t\u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgroundTruth_filename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     17\u001b[0m \t\tcontent \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     18\u001b[0m \tlines \u001b[38;5;241m=\u001b[39m [line\u001b[38;5;241m.\u001b[39mrstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m content[\u001b[38;5;241m2\u001b[39m:]]\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/groundTruth/auto/auto-kbb-model.txt'"
     ]
    }
   ],
   "source": [
    "#dataset processor: associate the ground truth label to each node\n",
    "attributes = ['model', 'manufacturer', 'price']\n",
    "from DatasetCreation.assignGroundTruthToEachNode import main\n",
    "main(Datapath, vertical, attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfm",
   "language": "python",
   "name": "tfm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
